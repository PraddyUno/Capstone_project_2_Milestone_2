# Capstone_project_2_Milestone_2

The main objective of this report was to evaluate the performance of the neural networks in detecting weather a tweet is hateful, offensive, or neither, against decision tree models. Text classification is subjective, i.e., one user can find the comment offensive while it might be neutral for another individual. Due to such issues, online communication platforms such as Facebook, Twitter, often have trouble on which side to support where free speech is protected. 
One obvious solution could be to mark all the tweets, comments, reviews, as hateful/offensive with a high frequency of abusive language. However, detecting profanity in the text can be challenging as the users often obfuscate the correct spellings such as a$$hole and b!! tch. A better approach would be to train a machine learning model to recognize structural patterns exhibited by the text documents belonging to a particular class.
Despite the fame and popularity, the neural networks have struggled in performance when compared with statistical models such as decisions trees. A recent empirical study [1], showed that in higher-dimensional problems, the random forest classifiers consistently outperformed the neural networks. Decision tree models require heavy preprocessing of the text data before training the classifiers. In comparison, neural networks can perform well on features with an intricate structure. Having a classifier that can perform well without too much computational cost can help curb the offensive/hateful language to appear on online platforms.
This report details the data mining, preprocessing, baseline models, and neural networks for multiclass classification of imbalance tweet dataset. 


[1] "An empirical evaluation of supervised learning in high dimensions," in 25th International Conference on Machine Learning, Helsinki, Finland, 2008. 
